services:
  web:
    build: ./app
    container_name: fastapi_app
    command: >
      bash -c "
      if [ \"$APP_ENV\" = 'production' ]; then 
        uvicorn main:app --host 0.0.0.0 --port 8000;
      else 
        uvicorn main:app --host 0.0.0.0 --port 8000 --reload;  
      fi"
    ports:
      - "8000:8000"
    environment:
      - CELERY_BROKER_URL=${CELERY_BROKER_URL-redis://redis:6379/0}
      - CELERY_RESULT_BACKEND=${CELERY_RESULT_BACKEND-redis://redis:6379/0}
      - LLM_PULL_API_URL=${LLM_PULL_API_URL-http://web:8000/llm_pull}
      - LLM_GENEREATE_API_URL=${LLM_GENEREATE_API_URL-http://web:8000/llm_generate}
      - OLLAMA_HOST${OLLAMA_HOST-http://ollama:11434}
      - APP_ENV=${APP_ENV-development}  # Default to development mode
    depends_on:
      - redis
      - ollama
    volumes:
      - ./app:/app  # Mount the app directory to enable auto-reloading      

  celery_worker:
    build: ./app
    container_name: celery_worker
    command: celery -A main.celery worker --loglevel=info
    environment:
      - OLLAMA_HOST=${OLLAMA_HOST-http://ollama:11434}
      - CELERY_BROKER_URL=${CELERY_BROKER_URL-redis://redis:6379/0}
      - CELERY_RESULT_BACKEND=${CELERY_RESULT_BACKEND-redis://redis:6379/0}
    depends_on:
      - redis
    volumes:
      - ./app:/app

  redis:
    image: redis:latest
    container_name: redis
    ports:
      - "6379:6379"


  ollama:
    image: ollama/ollama:0.4.0-rc6-rocm  # Use the official Ollama image
    container_name: ollama
    pull_policy: always
    tty: true
    restart: always
    ports:
      - "11434:11434"  # Expose Ollama's API port, changing internal to external port
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/"]  # Assumes health endpoint exists
      interval: 30s
      timeout: 10s
      retries: 3

